import gc
import os

from flask import Flask, request, jsonify
import threading
import cv2
import mediapipe as mp
import numpy as np
import base64
from flask_cors import CORS
from tensorflow.keras.models import load_model
import cv2
import numpy as np
import mediapipe as mp
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.sequence import pad_sequences
from collections import defaultdict
import time
import base64
import threading

app = Flask(__name__)
CORS(app, origins=["http://localhost:5014"])

# ------------------------ Shared State ------------------------
counter_pushup = 0
stage_pushup = None
error_pushup = None
counter = 0
stage = None
error = None
processing_active = False
current_frame = None
stop_processing = False
classification_result = None
processing_thread = None
sequence = []
frame_count = 0
seq_length = 50
classes = ['BodyWeightSquats', 'curl', 'JumpingJack', 'pushups', 'pullups', 'planko']
bicep_left_count = 0
bicep_right_count = 0
bicep_bad_left_form = False
bicep_bad_right_form = False
counter_jumping = 0
stage_jumping = None
error_jumping = None
pullup_count = 0
pullup_bad_form = ""
counter_leg_raises = 0
wrong_counter_leg_raises = 0
correct_bool_leg_raises = 0
stage_leg_raises = None
feedback_leg_raises = ""
error_left_front_raises = "None"
error_right_front_raises = "None"
counter_right_front_raises = 0
counter_left_front_raises = 0
counter_bench_press = 0
error_bench_press = "None"
camera_input = 0

# ------------------------ Rule-Based Bench Press ------------------------

def process_bench_press():
    global processing_active, stop_processing, current_frame
    global counter_bench_press, error_bench_press

    counter_bench_press = 0
    error_bench_press = "None"

    cap = cv2.VideoCapture(camera_input)

    mp_drawing = mp.solutions.drawing_utils
    mp_pose = mp.solutions.pose


    with mp.solutions.pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose_model:
        while processing_active and not stop_processing:
            ret, frame = cap.read()
            if not ret:
                break

            image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            results = pose_model.process(image_rgb)
            mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp.solutions.pose.POSE_CONNECTIONS)

            try:
                landmarks = results.pose_landmarks.landmark

                # Left arm
                left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,
                                 landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]
                left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,
                              landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]
                left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,
                              landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]
                left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,
                            landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]

                left_elbow_angle = calculate_angle(left_shoulder, left_elbow, left_wrist)
                left_armpit_angle = calculate_angle(left_hip, left_shoulder, left_elbow)

                # Right arm
                right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,
                                  landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]
                right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,
                               landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]
                right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,
                               landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]
                right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,
                             landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]

                right_elbow_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)
                right_armpit_angle = calculate_angle(right_hip, right_shoulder, right_elbow)

                # Visual indicators for armpit angles exceeding threshold
                ARMPIT_RANGE_THRESHOLD = 1000
                if left_armpit_angle > ARMPIT_RANGE_THRESHOLD or right_armpit_angle > ARMPIT_RANGE_THRESHOLD:
                    error_bench_press = "Your elbow is far from your body"

                ELBOW_RANGE_DOWN = 50
                ELBOW_RANGE_UP = 120

                angle = left_elbow_angle
                if (right_elbow_angle < left_elbow_angle) and stages == "down":
                    angle = right_elbow_angle
                if (right_elbow_angle > left_elbow_angle) and stages == "up":
                    angle = right_elbow_angle

                if angle < ELBOW_RANGE_DOWN:
                    stages = "down"
                if angle > ELBOW_RANGE_UP and stages == "down":
                    stages = "up"
                    counter_bench_press += 1

            except Exception as e:
                print("EXCEPTION:", e)
                pass

            _, jpeg = cv2.imencode('.jpg', frame)
            current_frame = base64.b64encode(jpeg).decode('utf-8')

        cap.release()
        processing_active = False


# ------------------------ Rule-Based Front Raises ------------------------

def process_front_raises():
    global processing_active, stop_processing, current_frame
    global error_left_front_raises, error_right_front_raises, counter_right_front_raises, counter_left_front_raises

    error_left_front_raises = "None"
    error_right_front_raises = "None"
    counter_right_front_raises = 0
    counter_left_front_raises = 0

    cap = cv2.VideoCapture(camera_input)

    mp_drawing = mp.solutions.drawing_utils
    mp_pose = mp.solutions.pose

    counters = {"left_correct": 0, "left_incorrect": 0, "right_correct": 0, "right_incorrect": 0}
    stages = {"left": None, "right": None}

    with mp.solutions.pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose_model:
        while processing_active and not stop_processing:
            ret, frame = cap.read()
            if not ret:
                break

            image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            results = pose_model.process(image_rgb)
            mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp.solutions.pose.POSE_CONNECTIONS)

            try:
                landmarks = results.pose_landmarks.landmark

                # Left arm
                left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,
                                 landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]
                left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,
                              landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]
                left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,
                              landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]
                left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,
                            landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]

                left_elbow_angle = calculate_angle(left_shoulder, left_elbow, left_wrist)
                left_armpit_angle = calculate_angle(left_hip, left_shoulder, left_elbow)

                # Right arm
                right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,
                                  landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]
                right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,
                               landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]
                right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,
                               landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]
                right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,
                             landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]

                right_elbow_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)
                right_armpit_angle = calculate_angle(right_hip, right_shoulder, right_elbow)

                # Visual indicators for armpit angles exceeding threshold
                ELBOW_RANGE_THRESHOLD = 120

                if left_elbow_angle < ELBOW_RANGE_THRESHOLD:
                    error_left_front_raises = "Your left elbow is not straight"

                if right_elbow_angle < ELBOW_RANGE_THRESHOLD:
                    error_left_front_raises = "Your right elbow is not straight"

                # Curl logic
                ARMPIT_RANGE_DOWN = 20
                ARMPIT_RANGE_UP = 85

                if left_armpit_angle < ARMPIT_RANGE_DOWN:
                    stages["left"] = "down"
                if left_armpit_angle > ARMPIT_RANGE_UP and stages["left"] == "down":
                    stages["left"] = "up"
                    if left_elbow_angle >= ELBOW_RANGE_THRESHOLD:
                        counters["left_correct"] += 1
                    else:
                        counters["left_incorrect"] += 1

                if right_armpit_angle < ARMPIT_RANGE_DOWN:
                    stages["right"] = "down"
                if right_armpit_angle > ARMPIT_RANGE_UP and stages["right"] == "down":
                    stages["right"] = "up"
                    if right_elbow_angle >= ELBOW_RANGE_THRESHOLD:
                        counters["right_correct"] += 1
                    else:
                        counters["right_incorrect"] += 1

                counter_right_front_raises = counters["right_correct"]
                counter_left_front_raises = counters["left_correct"]

            except Exception as e:
                print("EXCEPTION:", e)
                pass

            _, jpeg = cv2.imencode('.jpg', frame)
            current_frame = base64.b64encode(jpeg).decode('utf-8')

        cap.release()
        processing_active = False

# ------------------------ Rule-Based Leg Raises ------------------------

def calculate_angle_leg_raises(a, b, c):
    a, b, c = np.array(a), np.array(b), np.array(c)
    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])
    angle = np.abs(radians * 180.0 / np.pi)
    return 360 - angle if angle > 180.0 else angle

def process_leg_raises():
    global processing_active, stop_processing, current_frame
    global counter_leg_raises, wrong_counter_leg_raises, correct_bool_leg_raises
    global stage_leg_raises, feedback_leg_raises

    counter_leg_raises = 0
    wrong_counter_leg_raises = 0
    correct_bool_leg_raises = 0
    stage_leg_raises = None
    feedback_leg_raises = ""


    cap = cv2.VideoCapture(camera_input)

    mp_drawing = mp.solutions.drawing_utils
    mp_pose = mp.solutions.pose

    with mp.solutions.pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose_model:
        while processing_active and not stop_processing:
            ret, frame = cap.read()
            if not ret:
                break

            image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            results = pose_model.process(image_rgb)
            mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp.solutions.pose.POSE_CONNECTIONS)

            try:
                landmarks = results.pose_landmarks.landmark

                # Decide which leg to use based on visibility
                def vis_sum(part_ids):
                    return sum([landmarks[i].visibility for i in part_ids])

                left_vis = vis_sum([mp_pose.PoseLandmark.LEFT_SHOULDER.value, mp_pose.PoseLandmark.LEFT_HIP.value,
                                    mp_pose.PoseLandmark.LEFT_KNEE.value, mp_pose.PoseLandmark.LEFT_ANKLE.value])
                right_vis = vis_sum([mp_pose.PoseLandmark.RIGHT_SHOULDER.value, mp_pose.PoseLandmark.RIGHT_HIP.value,
                                     mp_pose.PoseLandmark.RIGHT_KNEE.value, mp_pose.PoseLandmark.RIGHT_ANKLE.value])
                use_left = left_vis > right_vis

                shoulder = [landmarks[
                                mp_pose.PoseLandmark.LEFT_SHOULDER.value if use_left else mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,
                            landmarks[
                                mp_pose.PoseLandmark.LEFT_SHOULDER.value if use_left else mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]
                hip = [landmarks[
                           mp_pose.PoseLandmark.LEFT_HIP.value if use_left else mp_pose.PoseLandmark.RIGHT_HIP.value].x,
                       landmarks[
                           mp_pose.PoseLandmark.LEFT_HIP.value if use_left else mp_pose.PoseLandmark.RIGHT_HIP.value].y]
                knee = [landmarks[
                            mp_pose.PoseLandmark.LEFT_KNEE.value if use_left else mp_pose.PoseLandmark.RIGHT_KNEE.value].x,
                        landmarks[
                            mp_pose.PoseLandmark.LEFT_KNEE.value if use_left else mp_pose.PoseLandmark.RIGHT_KNEE.value].y]
                ankle = [landmarks[
                             mp_pose.PoseLandmark.LEFT_ANKLE.value if use_left else mp_pose.PoseLandmark.RIGHT_ANKLE.value].x,
                         landmarks[
                             mp_pose.PoseLandmark.LEFT_ANKLE.value if use_left else mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]

                hip_angle = calculate_angle_leg_raises(shoulder, hip, knee)
                knee_angle = calculate_angle_leg_raises(hip, knee, ankle)

                if hip_angle > 150 and knee_angle > 160:
                    if stage_leg_raises == "middle" and not correct_bool_leg_raises:
                        wrong_counter_leg_raises += 1
                        feedback_leg_raises = "Raise your leg higher"
                    correct_bool_leg_raises = 0
                    stage_leg_raises = "down"
                elif hip_angle < 105 and knee_angle > 160:
                    if stage_leg_raises == "middle" and not correct_bool_leg_raises:
                        counter_leg_raises += 1
                        correct_bool_leg_raises = 1
                        feedback_leg_raises = "Correct Form"
                    stage_leg_raises = "up"
                elif hip_angle < 140:
                    stage_leg_raises = "middle"
                if knee_angle < 140:
                    feedback_leg_raises = "Straighten your leg"

            except Exception as e:
                print("Error in processing leg raise frame:", e)

            _, jpeg = cv2.imencode('.jpg', frame)
            current_frame = base64.b64encode(jpeg).decode('utf-8')

        cap.release()
        processing_active = False

# ------------------------ Rule-Based Pull ups ------------------------
def process_pullup():
    global pullup_count, pullup_bad_form, current_frame, processing_active, stop_processing

    mp_drawing = mp.solutions.drawing_utils
    mp_pose = mp.solutions.pose

    pullup_count = 0
    pullup_bad_form = ""
    stage = None
    reached_peak = False
    prev_head_y = None
    prev_direction = None

    cap = cv2.VideoCapture(camera_input)

    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose_model:
        while processing_active and not stop_processing:
            ret, frame = cap.read()
            if not ret:
                break

            image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            results = pose_model.process(image_rgb)
            mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp.solutions.pose.POSE_CONNECTIONS)

            try:
                landmarks = results.pose_landmarks.landmark

                head_y = landmarks[mp_pose.PoseLandmark.NOSE.value].y
                left_wrist_y = landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y
                right_wrist_y = landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y
                hand_y_min = min(left_wrist_y, right_wrist_y)

                # Detect direction of movement
                if prev_head_y is not None:
                    if head_y < prev_head_y - 0.01:
                        current_direction = "up"
                    elif head_y > prev_head_y + 0.01:
                        current_direction = "down"
                    else:
                        current_direction = prev_direction
                else:
                    current_direction = None
                prev_head_y = head_y

                previous_stage = stage
                stage = "up" if head_y < hand_y_min else "down"

                # Determine if peak was reached
                if stage == "up" and current_direction == "up":
                    reached_peak = True

                # Detect bad form
                if prev_direction == "up" and current_direction == "down":
                    if not reached_peak:
                        pullup_bad_form = "Did not reach peak"
                    reached_peak = False

                # Count valid rep
                if previous_stage == "up" and stage == "down":
                    pullup_count += 1
                    pullup_bad_form = ""

                prev_direction = current_direction

                _, jpeg = cv2.imencode('.jpg', frame)
                current_frame = base64.b64encode(jpeg).decode('utf-8')

            except Exception as e:
                print("EXCEPTION:", e)
                continue

        cap.release()
        processing_active = False

# ------------------------ Rule-Based Push ups ------------------------

def get_six_points_pushup(side, landmarks):
    """Extract six landmarks for chosen side."""
    mp_pose = mp.solutions.pose
    vals = mp_pose.PoseLandmark
    idx = side.upper()
    shoulder = [landmarks[vals[f"{idx}_SHOULDER"].value].x,
                landmarks[vals[f"{idx}_SHOULDER"].value].y]
    elbow = [landmarks[vals[f"{idx}_ELBOW"].value].x,
             landmarks[vals[f"{idx}_ELBOW"].value].y]
    wrist = [landmarks[vals[f"{idx}_WRIST"].value].x,
             landmarks[vals[f"{idx}_WRIST"].value].y]
    hip = [landmarks[vals[f"{idx}_HIP"].value].x,
           landmarks[vals[f"{idx}_HIP"].value].y]
    knee = [landmarks[vals[f"{idx}_KNEE"].value].x,
            landmarks[vals[f"{idx}_KNEE"].value].y]
    ankle = [landmarks[vals[f"{idx}_ANKLE"].value].x,
             landmarks[vals[f"{idx}_ANKLE"].value].y]
    return shoulder, elbow, wrist, hip, knee, ankle

def calculate_angle(a, b, c):
    """Calculate angle at point b formed by points a-b-c."""
    a, b, c = map(np.array, (a, b, c))
    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])
    angle = np.abs(radians * 180.0 / np.pi)
    return 360 - angle if angle > 180 else angle

def track_pushup(shoulder, elbow, wrist, hip, knee, ankle):
    """Update pushup counter, stage, and error based on key angles."""
    global counter_pushup, stage_pushup, error_pushup

    # Calculate relevant angles
    angle_elbow = calculate_angle(shoulder, elbow, wrist)
    angle_body = calculate_angle(shoulder, hip, knee)
    angle_shoulders = calculate_angle(elbow, shoulder, hip)
    angle_legs = calculate_angle(hip, knee, ankle)

    # Check if user is standing
    if angle_body > 175 and angle_legs > 175:
        error_pushup = 'User is standing'
        return

    # Repetition logic using elbow angle
    if angle_elbow >= 153:
        if stage_pushup == 'fin_pushup':
            counter_pushup += 1
            print(counter_pushup)
        stage_pushup = 'start_pushup'
    elif 45 < angle_elbow < 60:
        stage_pushup = 'fin_pushup'

    # Technique errors
    err_parts = []
    if angle_body < 163:
        err_parts.append('Hip too high')
    if angle_legs < 159:
        err_parts.append('Knee too bent')
    error_pushup = ' & '.join(err_parts) if err_parts else None

def process_pushup():
    global current_frame, processing_active, stop_processing
    global counter_pushup, stage_pushup, error_pushup

    mp_drawing = mp.solutions.drawing_utils
    mp_pose = mp.solutions.pose

    with mp.solutions.pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose_model:
        cap = cv2.VideoCapture(camera_input)

        while processing_active and not stop_processing:
            ret, frame = cap.read()
            if not ret:
                break

            image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            results = pose_model.process(image_rgb)
            mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp.solutions.pose.POSE_CONNECTIONS)

            if results.pose_landmarks:
                landmarks = results.pose_landmarks.landmark
                for side in ('left', 'right'):
                    vals = mp_pose.PoseLandmark
                    vis_list = [
                        landmarks[vals[f"{side.upper()}_{p}"].value].visibility
                        for p in ("SHOULDER", "ELBOW", "WRIST", "HIP", "KNEE", "ANKLE")
                    ]
                    if all(v > 0.5 for v in vis_list):
                        error_pushup = None
                        pts = get_six_points_pushup(side, landmarks)
                        track_pushup(*pts)
                        break
                    else:
                        error_pushup = 'Please show full body'

            _, jpeg = cv2.imencode('.jpg', frame)
            current_frame = base64.b64encode(jpeg).decode('utf-8')

        cap.release()
        processing_active = False

# ------------------------ Rule-Based Jumping ------------------------
# Get key points needed for Jumping Jack
def get_points_jumping_jack(landmarks):
    shoulder_left = [landmarks[mp.solutions.pose.PoseLandmark.LEFT_SHOULDER.value].x,
                     landmarks[mp.solutions.pose.PoseLandmark.LEFT_SHOULDER.value].y]
    shoulder_right = [landmarks[mp.solutions.pose.PoseLandmark.RIGHT_SHOULDER.value].x,
                      landmarks[mp.solutions.pose.PoseLandmark.RIGHT_SHOULDER.value].y]
    wrist_left = [landmarks[mp.solutions.pose.PoseLandmark.LEFT_WRIST.value].x,
                  landmarks[mp.solutions.pose.PoseLandmark.LEFT_WRIST.value].y]
    wrist_right = [landmarks[mp.solutions.pose.PoseLandmark.RIGHT_WRIST.value].x,
                   landmarks[mp.solutions.pose.PoseLandmark.RIGHT_WRIST.value].y]
    ankle_left = [landmarks[mp.solutions.pose.PoseLandmark.LEFT_ANKLE.value].x,
                  landmarks[mp.solutions.pose.PoseLandmark.LEFT_ANKLE.value].y]
    ankle_right = [landmarks[mp.solutions.pose.PoseLandmark.RIGHT_ANKLE.value].x,
                   landmarks[mp.solutions.pose.PoseLandmark.RIGHT_ANKLE.value].y]

    return shoulder_left, shoulder_right, wrist_left, wrist_right, ankle_left, ankle_right

# Calculate vertical distance
def calculate_vertical_distance(a, b):
    a, b = np.array(a), np.array(b)
    return abs(b[1] - a[1])

# Calculate horizontal distance
def calculate_horizontal_distance(a, b):
    a, b = np.array(a), np.array(b)
    return abs(b[0] - a[0])

# Tracking logic for Jumping Jacks
def track_jumping_jack(shoulder_left, shoulder_right, wrist_left, wrist_right, ankle_left, ankle_right):
    global counter_jumping, stage_jumping, error_jumping

    # Average vertical wrist position relative to shoulders
    wrist_height = (wrist_left[1] + wrist_right[1]) / 2
    shoulder_height = (shoulder_left[1] + shoulder_right[1]) / 2

    # Horizontal spread of ankles
    leg_distance = calculate_horizontal_distance(ankle_left, ankle_right)

    # Heuristic rules
    if wrist_height < shoulder_height and leg_distance > 0.3:  # Arms up & legs apart
        if stage_jumping == 'down':
            counter_jumping += 1
        stage_jumping = 'up'
    elif wrist_height > shoulder_height and leg_distance < 0.2:  # Arms down & legs together
        stage_jumping = 'down'

    error_jumping = None  # Only set when points are missing (handled elsewhere)

# Processing function
def process_jumping_jack():
    global counter_jumping, stage_jumping, error_jumping, current_frame, processing_active, stop_processing

    mp_drawing = mp.solutions.drawing_utils
    with mp.solutions.pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose_model:
        cap = cv2.VideoCapture(camera_input)

        while processing_active and not stop_processing:
            ret, frame = cap.read()
            if not ret:
                break

            image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            results = pose_model.process(image_rgb)
            mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp.solutions.pose.POSE_CONNECTIONS)

            if results.pose_landmarks:
                landmarks = results.pose_landmarks.landmark
                vis = lambda idx: landmarks[idx].visibility > 0.5

                required_points = [
                    mp.solutions.pose.PoseLandmark.LEFT_SHOULDER.value,
                    mp.solutions.pose.PoseLandmark.RIGHT_SHOULDER.value,
                    mp.solutions.pose.PoseLandmark.LEFT_WRIST.value,
                    mp.solutions.pose.PoseLandmark.RIGHT_WRIST.value,
                    mp.solutions.pose.PoseLandmark.LEFT_ANKLE.value,
                    mp.solutions.pose.PoseLandmark.RIGHT_ANKLE.value
                ]

                if all([vis(idx) for idx in required_points]):
                    points = get_points_jumping_jack(landmarks)
                    track_jumping_jack(*points)
                else:
                    error_jumping = "Not All Points Are Showing"

            _, jpeg = cv2.imencode('.jpg', frame)
            current_frame = base64.b64encode(jpeg).decode('utf-8')

        cap.release()
        processing_active = False

# ------------------------ Rule-Based Squat ------------------------
def get_four_points_squat(side, landmarks):
    if side == "left":
        foot_idx = [landmarks[mp.solutions.pose.PoseLandmark.LEFT_FOOT_INDEX.value].x,
                    landmarks[mp.solutions.pose.PoseLandmark.LEFT_FOOT_INDEX.value].y]
        hip = [landmarks[mp.solutions.pose.PoseLandmark.LEFT_HIP.value].x,
               landmarks[mp.solutions.pose.PoseLandmark.LEFT_HIP.value].y]
        knee = [landmarks[mp.solutions.pose.PoseLandmark.LEFT_KNEE.value].x,
                landmarks[mp.solutions.pose.PoseLandmark.LEFT_KNEE.value].y]
        ankle = [landmarks[mp.solutions.pose.PoseLandmark.LEFT_ANKLE.value].x,
                 landmarks[mp.solutions.pose.PoseLandmark.LEFT_ANKLE.value].y]
    else:
        foot_idx = [landmarks[mp.solutions.pose.PoseLandmark.RIGHT_FOOT_INDEX.value].x,
                    landmarks[mp.solutions.pose.PoseLandmark.RIGHT_FOOT_INDEX.value].y]
        hip = [landmarks[mp.solutions.pose.PoseLandmark.RIGHT_HIP.value].x,
               landmarks[mp.solutions.pose.PoseLandmark.RIGHT_HIP.value].y]
        knee = [landmarks[mp.solutions.pose.PoseLandmark.RIGHT_KNEE.value].x,
                landmarks[mp.solutions.pose.PoseLandmark.RIGHT_KNEE.value].y]
        ankle = [landmarks[mp.solutions.pose.PoseLandmark.RIGHT_ANKLE.value].x,
                 landmarks[mp.solutions.pose.PoseLandmark.RIGHT_ANKLE.value].y]
    return foot_idx, hip, knee, ankle

def calculate_angle(a, b, c):
    a, b, c = np.array(a), np.array(b), np.array(c)
    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])
    angle = np.abs(radians * 180.0 / np.pi)
    return 360 - angle if angle > 180.0 else angle

def calculate_dis(a, b):
    a, b = np.array(a), np.array(b)
    return b[0] - a[0]

def track_squat(foot_idx, hip, knee, ankle):
    global counter, stage, error
    angle = calculate_angle(hip, knee, ankle)
    dis = calculate_dis(knee, foot_idx)

    if angle >= 150:
        if stage == 'fin':
            counter += 1
        stage = 'start'
    elif 60 < angle < 100:
        stage = 'fin'

    error = "Knee too forward" if dis >= 0.09 and angle < 100 else None

def process_squat():
    global counter, stage, error, current_frame, processing_active, stop_processing

    mp_drawing = mp.solutions.drawing_utils
    with mp.solutions.pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose_model:
        cap = cv2.VideoCapture(camera_input)

        while processing_active and not stop_processing:
            ret, frame = cap.read()
            if not ret:
                break

            image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            results = pose_model.process(image_rgb)
            mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp.solutions.pose.POSE_CONNECTIONS)

            if results.pose_landmarks:
                landmarks = results.pose_landmarks.landmark
                vis = lambda idx: landmarks[idx].visibility > 0.5
                if all([vis(mp.solutions.pose.PoseLandmark.LEFT_HIP.value),
                        vis(mp.solutions.pose.PoseLandmark.LEFT_KNEE.value),
                        vis(mp.solutions.pose.PoseLandmark.LEFT_ANKLE.value),
                        vis(mp.solutions.pose.PoseLandmark.LEFT_FOOT_INDEX.value)]):
                    pts = get_four_points_squat("left", landmarks)
                    track_squat(*pts)
                elif all([vis(mp.solutions.pose.PoseLandmark.RIGHT_HIP.value),
                          vis(mp.solutions.pose.PoseLandmark.RIGHT_KNEE.value),
                          vis(mp.solutions.pose.PoseLandmark.RIGHT_ANKLE.value),
                          vis(mp.solutions.pose.PoseLandmark.RIGHT_FOOT_INDEX.value)]):
                    pts = get_four_points_squat("right", landmarks)
                    track_squat(*pts)
                else:
                    error = "Not All Points Are showing"

            _, jpeg = cv2.imencode('.jpg', frame)
            current_frame = base64.b64encode(jpeg).decode('utf-8')

        cap.release()
        processing_active = False

# ------------------------ Rule-Based Bicep ------------------------

def process_bicep():
    global bicep_left_count, bicep_right_count, bicep_bad_left_form, bicep_bad_right_form, current_frame, processing_active, stop_processing

    mp_drawing = mp.solutions.drawing_utils
    mp_pose = mp.solutions.pose

    # Reset counters and flags
    bicep_left_count = 0
    bicep_right_count = 0
    bicep_bad_left_form = False
    bicep_bad_right_form = False

    counters = {"left": 0, "right": 0}
    stages = {"left": None, "right": None}

    cap = cv2.VideoCapture(camera_input)  # Use webcam (change to video file path if needed)

    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:
        while processing_active and not stop_processing:
            ret, frame = cap.read()
            if not ret:
                break

            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            image.flags.writeable = False
            results = pose.process(image)
            image.flags.writeable = True
            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)

            try:
                landmarks = results.pose_landmarks.landmark

                left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,
                                 landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]
                left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,
                              landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]
                left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,
                              landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]
                left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,
                            landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]

                right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,
                                  landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]
                right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,
                               landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]
                right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,
                               landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]
                right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,
                             landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]

                left_elbow_angle = calculate_angle(left_shoulder, left_elbow, left_wrist)
                left_armpit_angle = calculate_angle(left_hip, left_shoulder, left_elbow)
                right_elbow_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)
                right_armpit_angle = calculate_angle(right_hip, right_shoulder, right_elbow)

                ARMPIT_RANGE_THRESHOLD = 20
                if left_armpit_angle > ARMPIT_RANGE_THRESHOLD:
                    bicep_bad_left_form = True
                else:
                    bicep_bad_left_form = False

                if right_armpit_angle > ARMPIT_RANGE_THRESHOLD:
                    bicep_bad_right_form = True
                else:
                    bicep_bad_right_form = False

                ELBOW_RANGE_DOWN = 160
                ELBOW_RANGE_UP = 30

                if left_elbow_angle > ELBOW_RANGE_DOWN:
                    stages["left"] = "down"
                if left_elbow_angle < ELBOW_RANGE_UP and stages["left"] == "down":
                    stages["left"] = "up"
                    if left_armpit_angle <= ARMPIT_RANGE_THRESHOLD:
                        counters["left"] += 1
                        bicep_left_count = counters["left"]

                if right_elbow_angle > ELBOW_RANGE_DOWN:
                    stages["right"] = "down"
                if right_elbow_angle < ELBOW_RANGE_UP and stages["right"] == "down":
                    stages["right"] = "up"
                    if right_armpit_angle <= ARMPIT_RANGE_THRESHOLD:
                        counters["right"] += 1
                        bicep_right_count = counters["right"]

            except Exception as e:
                print("EXCEPTION:", e)
                pass

            # Draw landmarks (using same style as squat detection)
            if results.pose_landmarks:
                mp_drawing.draw_landmarks(
                    image,
                    results.pose_landmarks,
                    mp_pose.POSE_CONNECTIONS,
                    mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=2),  # Red keypoints
                    mp_drawing.DrawingSpec(color=(245, 245, 245), thickness=2, circle_radius=2)  # Off-white connections
                )

                # Encode frame for sending to frontend
                _, jpeg = cv2.imencode('.jpg', image)
                current_frame = base64.b64encode(jpeg).decode('utf-8')

        cap.release()
        processing_active = False

# ------------------------ LSTM Classification ------------------------

# -----------------------------
# Configuration
# -----------------------------
class_model = load_model(r"D:\FCIS\Fourth Year\GP\Application\Python Models\lstm_model.h5")
CLASS_NAMES_classification = ["BodyWeightSquats", "JumpingJack", "PullUps", "PushUps", "plank", "curl"]
INDEX_TO_LABEL_classification = {0: "BodyWeightSquats", 1: "JumpingJack", 2: "PullUps", 3: "PushUps", 4: "curl", 5: "plank"}

# MediaPipe Pose setup
mp_pose_classification = mp.solutions.pose
pose_classification = mp_pose_classification.Pose(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)

# -----------------------------
# Pose Landmarks and Angles
# -----------------------------

BODY_POINTS_classification = {
    0: "nose", 1: "left_eye_inner", 2: "left_eye", 3: "left_eye_outer",
    4: "right_eye_inner", 5: "right_eye", 6: "right_eye_outer",
    7: "left_ear", 8: "right_ear", 9: "mouth_left", 10: "mouth_right",
    11: "left_shoulder", 12: "right_shoulder", 13: "left_elbow", 14: "right_elbow",
    15: "left_wrist", 16: "right_wrist", 17: "left_pinky", 18: "right_pinky",
    19: "left_index", 20: "right_index", 21: "left_thumb", 22: "right_thumb",
    23: "left_hip", 24: "right_hip", 25: "left_knee", 26: "right_knee",
    27: "left_ankle", 28: "right_ankle", 29: "left_heel", 30: "right_heel",
    31: "left_foot_index", 32: "right_foot_index"
}

ANGLES_classification = {
    "left_wrist": [15, 13, 11],
    "right_wrist": [16, 14, 12],
    "left_elbow": [13, 11, 23],
    "right_elbow": [14, 12, 24],
    "left_armpit": [11, 13, 15],
    "right_armpit": [12, 14, 16],
    "left_hip": [23, 11, 13],
    "right_hip": [24, 12, 14],
    "left_knee": [25, 23, 11],
    "right_knee": [26, 24, 12],
    "left_ankle": [27, 25, 23],
    "right_ankle": [28, 26, 24]
}

# -----------------------------
# Utility Functions
# -----------------------------

def calculate_angle_classification(a, b, c):
    ab = np.array(b) - np.array(a)
    bc = np.array(c) - np.array(b)
    cosine = np.dot(ab, bc) / (np.linalg.norm(ab) * np.linalg.norm(bc))
    return np.degrees(np.arccos(np.clip(cosine, -1, 1)))

def process_frame_classification(frame, frame_buffer, max_frames=35):
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    results = pose_classification.process(frame_rgb)

    if results.pose_landmarks:
        keypoints = {}
        for idx, name in BODY_POINTS_classification.items():
            landmark = results.pose_landmarks.landmark[idx]
            keypoints[f"{name}_x"] = landmark.x
            keypoints[f"{name}_y"] = landmark.y
            keypoints[f"{name}_z"] = landmark.z
            keypoints[f"{name}_visibility"] = landmark.visibility

        angles = {}
        for angle_name, points in ANGLES_classification.items():
            a = (results.pose_landmarks.landmark[points[0]].x,
                 results.pose_landmarks.landmark[points[0]].y,
                 results.pose_landmarks.landmark[points[0]].z)
            b = (results.pose_landmarks.landmark[points[1]].x,
                 results.pose_landmarks.landmark[points[1]].y,
                 results.pose_landmarks.landmark[points[1]].z)
            c = (results.pose_landmarks.landmark[points[2]].x,
                 results.pose_landmarks.landmark[points[2]].y,
                 results.pose_landmarks.landmark[points[2]].z)
            angles[angle_name] = calculate_angle_classification(a, b, c)

        frame_buffer.append({**keypoints, **angles})
        if len(frame_buffer) > max_frames:
            frame_buffer.pop(0)

    return frame_buffer

def predict_action_classification(frame_buffer, model, max_length, index_to_label):
    if not frame_buffer:
        return "No pose detected", 0.0

    sequence = np.array([list(frame.values()) for frame in frame_buffer])
    padded = pad_sequences([sequence], maxlen=max_length, padding="post", dtype="float32")

    prediction = model.predict(padded, verbose=0)[0]
    pred_index = np.argmax(prediction)
    confidence = float(prediction[pred_index])

    return index_to_label.get(pred_index, "Unknown"), confidence

# -----------------------------
# Main Classification Loop
# -----------------------------

final_confidence_classification = 0.0
final_prediction_classification = "Evaluating..."
prediction_lock_classification = threading.Lock()
prediction_ready_classification = threading.Event()
current_frame = None
processing_active_classification = True

def prediction_worker_classification(frame_buffer_copy, model, max_length, index_to_label, prediction_history):
    pred, conf = predict_action_classification(frame_buffer_copy, model, max_length, index_to_label)
    with prediction_lock_classification:
        prediction_history.append((pred, conf))
    prediction_ready_classification.set()

def live_classification(model, max_length, index_to_label):
    global final_prediction_classification, final_confidence_classification
    global current_frame, processing_active
    global bicep_left_count, bicep_right_count, bicep_bad_left_form, bicep_bad_right_form
    global counter, stage, error
    global counter_jumping, stage_jumping, error_jumping
    global counter_pushup, stage_pushup, error_pushup
    global pullup_count, pullup_bad_form, current_frame, processing_active, stop_processing

    cap = cv2.VideoCapture(camera_input)

    frame_buffer = []
    prediction_history = []

    # Reset bicep counters and flags
    bicep_left_count = 0
    bicep_right_count = 0
    bicep_bad_left_form = False
    bicep_bad_right_form = False
    counters_prv = {"left": 0, "right": 0}
    stages_prv = {"left": None, "right": None}
    bad_form_flags_prv = {"left": False, "right": False}

    # Reset Squat counters and flags
    counter_squat_prev = 0
    error_squat_prev = 0
    counter = 0
    stage = None
    error = None

    #Reset Jumping flags
    counter_jumping = 0
    error_jumping = None
    stage_jumping = None
    counter_jumping_prev = 0
    error_jumping_prev = None

    #Reset Pushups flags
    counter_pushup = 0
    stage_pushup = None
    error_pushup = None
    counter_pushup_prev = 0
    error_pushup_prev = None
    mp_pose = mp.solutions.pose

    #pullup flags
    pullup_count = 0
    pullup_bad_form = ""
    pullup_count_prev = 0
    pullup_bad_form_prev = ""
    stage_pullup = None
    reached_peak = False
    prev_head_y = None
    prev_direction = None

    print("Initializing camera and pose detection...")

    while len(frame_buffer) < 5:
        ret, frame = cap.read()
        if not ret:
            continue
        frame_buffer = process_frame_classification(frame, frame_buffer)

    print("Starting 5-second evaluation...")

    start_time = time.time()
    last_pred_time = start_time
    final_prediction_classification = "Evaluating..."
    final_confidence_classification = 0.0

    with mp_pose_classification.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:
        prediction_thread = None

        while cap.isOpened() and processing_active and processing_active:
            ret, frame = cap.read()
            if not ret:
                break

            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            results = pose.process(frame_rgb)

            # Draw landmarks
            annotated_frame = frame.copy()
            if results.pose_landmarks:
                mp.solutions.drawing_utils.draw_landmarks(
                    annotated_frame, results.pose_landmarks, mp_pose_classification.POSE_CONNECTIONS)

            # Classification: every second during first 5 seconds
            current_time = time.time()
            elapsed = current_time - start_time

            frame_buffer = process_frame_classification(frame, frame_buffer)

            if elapsed <= 5.0:
                if current_time - last_pred_time >= 1.0 and (not prediction_thread or not prediction_thread.is_alive()):
                    frame_buffer_copy = frame_buffer.copy()
                    prediction_ready_classification.clear()
                    prediction_thread = threading.Thread(
                        target=prediction_worker_classification,
                        args=(frame_buffer_copy, model, max_length, index_to_label, prediction_history)
                    )
                    prediction_thread.start()
                    last_pred_time = current_time

            elif final_prediction_classification == "Evaluating...":
                if prediction_thread:
                    prediction_thread.join()

                with prediction_lock_classification:
                    pred_counts = defaultdict(int)
                    conf_sums = defaultdict(float)
                    for pred, conf in prediction_history:
                        pred_counts[pred] += 1
                        conf_sums[pred] += conf

                    if pred_counts:
                        final_prediction_classification = max(pred_counts, key=pred_counts.get)
                        final_confidence_classification = conf_sums[final_prediction_classification] / pred_counts[final_prediction_classification]
                    else:
                        final_prediction_classification = "NOTHING"
                        final_confidence_classification = 0.0

                if final_prediction_classification == "plank":
                    print("Prediction was 'plank'. Exiting.")
                    break

                del model
                gc.collect()
                print("Classification model unloaded from memory.")

            else:
                # After classification ends, sync bicep values for frontend
                bicep_left_count = counters_prv["left"]
                bicep_right_count = counters_prv["right"]
                bicep_bad_left_form = int(bad_form_flags_prv["left"])
                bicep_bad_right_form = int(bad_form_flags_prv["right"])
                counter = counter_squat_prev
                error = error_squat_prev
                counter_jumping = counter_jumping_prev
                error_jumping = error_jumping_prev
                counter_pushup = counter_pushup_prev
                error_pushup = error_pushup_prev
                pullup_count = pullup_count_prev
                pullup_bad_form = pullup_bad_form_prev

            # Encode frame for frontend
            _, jpeg = cv2.imencode('.jpg', annotated_frame)
            current_frame = base64.b64encode(jpeg).decode('utf-8')

            # 1) Bicep logic
            try:
                landmarks_prv = results.pose_landmarks.landmark

                def get_landmark_prv(name):
                    return [
                        landmarks_prv[mp_pose_classification.PoseLandmark[name].value].x,
                        landmarks_prv[mp_pose_classification.PoseLandmark[name].value].y
                    ]

                left_shoulder_prv = get_landmark_prv("LEFT_SHOULDER")
                left_elbow_prv = get_landmark_prv("LEFT_ELBOW")
                left_wrist_prv = get_landmark_prv("LEFT_WRIST")
                left_hip_prv = get_landmark_prv("LEFT_HIP")

                right_shoulder_prv = get_landmark_prv("RIGHT_SHOULDER")
                right_elbow_prv = get_landmark_prv("RIGHT_ELBOW")
                right_wrist_prv = get_landmark_prv("RIGHT_WRIST")
                right_hip_prv = get_landmark_prv("RIGHT_HIP")

                left_elbow_angle_prv = calculate_angle(left_shoulder_prv, left_elbow_prv, left_wrist_prv)
                left_armpit_angle_prv = calculate_angle(left_hip_prv, left_shoulder_prv, left_elbow_prv)
                right_elbow_angle_prv = calculate_angle(right_shoulder_prv, right_elbow_prv, right_wrist_prv)
                right_armpit_angle_prv = calculate_angle(right_hip_prv, right_shoulder_prv, right_elbow_prv)

                ARMPIT_THRESHOLD = 20
                bad_form_flags_prv["left"] = left_armpit_angle_prv > ARMPIT_THRESHOLD
                bad_form_flags_prv["right"] = right_armpit_angle_prv > ARMPIT_THRESHOLD

                ELBOW_DOWN = 160
                ELBOW_UP = 30

                if left_elbow_angle_prv > ELBOW_DOWN:
                    stages_prv["left"] = "down"
                if left_elbow_angle_prv < ELBOW_UP and stages_prv["left"] == "down":
                    stages_prv["left"] = "up"
                    if not bad_form_flags_prv["left"]:
                        counters_prv["left"] += 1
                        print(f"[LEFT BICEP COUNT] {counters_prv['left']}")

                if right_elbow_angle_prv > ELBOW_DOWN:
                    stages_prv["right"] = "down"
                if right_elbow_angle_prv < ELBOW_UP and stages_prv["right"] == "down":
                    stages_prv["right"] = "up"
                    if not bad_form_flags_prv["right"]:
                        counters_prv["right"] += 1
                        print(f"[RIGHT BICEP COUNT] {counters_prv['right']}")
            except Exception as e:
                print("Exception in bicep logic:", e)

            # 2) Squat logic
            if results.pose_landmarks:
                landmarks = results.pose_landmarks.landmark
                vis = lambda idx: landmarks[idx].visibility > 0.5
                if all([vis(mp.solutions.pose.PoseLandmark.LEFT_HIP.value),
                        vis(mp.solutions.pose.PoseLandmark.LEFT_KNEE.value),
                        vis(mp.solutions.pose.PoseLandmark.LEFT_ANKLE.value),
                        vis(mp.solutions.pose.PoseLandmark.LEFT_FOOT_INDEX.value)]):
                    foot_idx, hip, knee, ankle = get_four_points_squat("left", landmarks)
                    angle = calculate_angle(hip, knee, ankle)
                    dis = calculate_dis(knee, foot_idx)
                    if angle >= 150:
                        if stage == 'fin':
                            counter_squat_prev += 1
                        stage = 'start'
                    elif 60 < angle < 100:
                        stage = 'fin'
                    error_squat_prev = "Knee too forward" if dis >= 0.09 and angle < 100 else None
                elif all([vis(mp.solutions.pose.PoseLandmark.RIGHT_HIP.value),
                          vis(mp.solutions.pose.PoseLandmark.RIGHT_KNEE.value),
                          vis(mp.solutions.pose.PoseLandmark.RIGHT_ANKLE.value),
                          vis(mp.solutions.pose.PoseLandmark.RIGHT_FOOT_INDEX.value)]):
                    foot_idx, hip, knee, ankle = get_four_points_squat("right", landmarks)
                    angle = calculate_angle(hip, knee, ankle)
                    dis = calculate_dis(knee, foot_idx)
                    print("SQUAT: ")
                    print(counter_squat_prev)
                    print(stage)
                    print(angle)
                    if angle >= 150:
                        if stage == 'fin':
                            counter_squat_prev += 1
                        stage = 'start'
                    elif 60 < angle < 100:
                        stage = 'fin'
                    error_squat_prev = "Knee too forward" if dis >= 0.09 and angle < 100 else None
                else:
                    error_squat_prev = "Not All Points Are showing"

            # 3) jumping jack logic
            if results.pose_landmarks:
                landmarks = results.pose_landmarks.landmark
                vis = lambda idx: landmarks[idx].visibility > 0.0

                required_points = [
                    mp.solutions.pose.PoseLandmark.LEFT_SHOULDER.value,
                    mp.solutions.pose.PoseLandmark.RIGHT_SHOULDER.value,
                    mp.solutions.pose.PoseLandmark.LEFT_WRIST.value,
                    mp.solutions.pose.PoseLandmark.RIGHT_WRIST.value,
                    mp.solutions.pose.PoseLandmark.LEFT_ANKLE.value,
                    mp.solutions.pose.PoseLandmark.RIGHT_ANKLE.value
                ]

                if all([vis(idx) for idx in required_points]):
                    shoulder_left, shoulder_right, wrist_left, wrist_right, ankle_left, ankle_right = get_points_jumping_jack(landmarks)
                    # Average vertical wrist position relative to shoulders
                    wrist_height = (wrist_left[1] + wrist_right[1]) / 2
                    shoulder_height = (shoulder_left[1] + shoulder_right[1]) / 2
                    # Horizontal spread of ankles
                    leg_distance = calculate_horizontal_distance(ankle_left, ankle_right)
                    # Heuristic rules
                    if wrist_height < shoulder_height and leg_distance > 0.3:  # Arms up & legs apart
                        if stage_jumping == 'down':
                            counter_jumping_prev += 1
                        stage_jumping = 'up'
                    elif wrist_height > shoulder_height and leg_distance < 0.2:  # Arms down & legs together
                        stage_jumping = 'down'

                    error_jumping_prev = None  # Only set when points are missing (handled elsewhere)
                else:
                    error_jumping_prev = "Not All Points Are Showing"

            #4) pushup logic
            if results.pose_landmarks:
                landmarks = results.pose_landmarks.landmark
                for side in ('left', 'right'):
                    vals = mp_pose.PoseLandmark
                    vis_list = [
                        landmarks[vals[f"{side.upper()}_{p}"].value].visibility
                        for p in ("SHOULDER", "ELBOW", "WRIST", "HIP", "KNEE", "ANKLE")
                    ]
                    if all(v > 0.5 for v in vis_list):
                        error_pushup = None
                        shoulder, elbow, wrist, hip, knee, ankle = get_six_points_pushup(side, landmarks)
                        # Calculate relevant angles
                        angle_elbow = calculate_angle(shoulder, elbow, wrist)
                        angle_body = calculate_angle(shoulder, hip, knee)
                        angle_shoulders = calculate_angle(elbow, shoulder, hip)
                        angle_legs = calculate_angle(hip, knee, ankle)

                        # Check if user is standing
                        if angle_body > 175 and angle_legs > 175:
                            error_pushup_prev = 'User is standing'
                            break

                        # Repetition logic using elbow angle
                        if angle_elbow >= 153:
                            if stage_pushup == 'fin_pushup':
                                counter_pushup_prev += 1
                            stage_pushup = 'start_pushup'
                        elif 45 < angle_elbow < 60:
                            stage_pushup = 'fin_pushup'

                        # Technique errors
                        err_parts = []
                        if angle_body < 163:
                            err_parts.append('Hip too high')
                        if angle_legs < 159:
                            err_parts.append('Knee too bent')
                        error_pushup_prev = ' & '.join(err_parts) if err_parts else None

                        break
                    else:
                        error_pushup_prev = 'Please show full body'

            #5) pullup logic
            try:
                landmarks = results.pose_landmarks.landmark

                head_y = landmarks[mp_pose.PoseLandmark.NOSE.value].y
                left_wrist_y = landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y
                right_wrist_y = landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y
                hand_y_min = min(left_wrist_y, right_wrist_y)

                # Detect direction of movement
                if prev_head_y is not None:
                    if head_y < prev_head_y - 0.01:
                        current_direction = "up"
                    elif head_y > prev_head_y + 0.01:
                        current_direction = "down"
                    else:
                        current_direction = prev_direction
                else:
                    current_direction = None
                prev_head_y = head_y

                previous_stage = stage
                stage_pullup = "up" if head_y < hand_y_min else "down"

                # Determine if peak was reached
                if stage_pullup == "up" and current_direction == "up":
                    reached_peak = True

                # Detect bad form
                if prev_direction == "up" and current_direction == "down":
                    if not reached_peak:
                        pullup_bad_form_prev = "Did not reach peak"
                    reached_peak = False

                # Count valid rep
                if previous_stage == "up" and stage_pullup == "down":
                    pullup_count_prev += 1
                    pullup_bad_form_prev = ""

                prev_direction = current_direction
            except Exception as e:
                print("EXCEPTION:", e)

    cap.release()
    cv2.destroyAllWindows()
    processing_active = False
    print("Session ended. Camera and resources released.")

# ------------------------ Plank ------------------------
import pickle

plank_model = load_model(r"D:\FCIS\Fourth Year\GP\Application\Python Models\plank_correction_model.h5")
with open(r"D:\FCIS\Fourth Year\GP\Application\Python Models\input_scaler.pkl", "rb") as f:
    plank_scaler = pickle.load(f)

plank_feedback = {
    0: "Your plank is correct!",
    1: "Your hips are too high! Try lowering them.",
    2: "Your hips are too low! Try raising them."
}
plank_result = None

IMPORTANT_LMS = [
    "NOSE", "LEFT_SHOULDER", "RIGHT_SHOULDER", "LEFT_ELBOW", "RIGHT_ELBOW",
    "LEFT_WRIST", "RIGHT_WRIST", "LEFT_HIP", "RIGHT_HIP", "LEFT_KNEE",
    "RIGHT_KNEE", "LEFT_ANKLE", "RIGHT_ANKLE", "LEFT_HEEL", "RIGHT_HEEL",
    "LEFT_FOOT_INDEX", "RIGHT_FOOT_INDEX"
]

def extract_landmarks_plank(results):
    if not results.pose_landmarks:
        return None
    landmarks = []
    for lm in IMPORTANT_LMS:
        idx = getattr(mp.solutions.pose.PoseLandmark, lm).value
        landmark = results.pose_landmarks.landmark[idx]
        landmarks.extend([landmark.x, landmark.y, landmark.z, landmark.visibility])
    return landmarks

def process_plank_correction():
    global processing_active, stop_processing, current_frame, plank_result

    mp_drawing = mp.solutions.drawing_utils
    with mp.solutions.pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:
        cap = cv2.VideoCapture(camera_input)  # Change to webcam if needed

        while processing_active and not stop_processing:
            ret, frame = cap.read()
            if not ret:
                break

            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            results = pose.process(rgb_frame)
            mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp.solutions.pose.POSE_CONNECTIONS)

            landmarks = extract_landmarks_plank(results)
            if landmarks:
                x_input = np.array(landmarks).reshape(1, -1)
                x_input = plank_scaler.transform(x_input)
                prediction = plank_model.predict(x_input)
                predicted_class = np.argmax(prediction)

                plank_result = {
                    "feedback": plank_feedback[predicted_class],
                    "confidence": float(prediction[0][predicted_class])
                }

                # cv2.putText(frame, plank_result["feedback"], (50, 50),
                #             cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)

            _, jpeg = cv2.imencode('.jpg', frame)
            current_frame = base64.b64encode(jpeg).decode('utf-8')

        cap.release()
        cv2.destroyAllWindows()
        processing_active = False

# ------------------------ Routes ------------------------
@app.route('/start', methods=['POST'])
def start_process():
    global processing_active, stop_processing, counter, stage, error, classification_result, processing_thread
    global counter_jumping, stage_jumping, error_jumping
    global camera_input

    #Select Camera OR Updoad Video
    if request.content_type.startswith('multipart/form-data'):
        trigger = request.form.get("trigger")
        mode = request.form.get("camera-mode")

        print("Trigger received:", trigger)
        print("Camera mode received:", mode)

        if trigger == "camera-mode-selection":
            print("SELECTING CAMERA MODE")
            if mode == "webcam":
                camera_input = 0
                print("Camera input selected:", camera_input)
            else:
                VIDEO_SAVE_PATH = r'D:\FCIS\Fourth Year\GP\Application\GEMS\Videos'
                video_file = request.files.get("video-file")  # important!
                if video_file:
                    os.makedirs(VIDEO_SAVE_PATH, exist_ok=True)
                    camera_input = os.path.join(VIDEO_SAVE_PATH, video_file.filename)
                    video_file.save(camera_input)
                    print("Saved video to:", camera_input)
                else:
                    print("No video file received")
        else:
            print("Unknown trigger:", trigger)

        return jsonify({"status": "success"}), 200

    data = request.get_json()

    # STOP trigger
    if data and data.get("trigger") == "stop":
        stop_processing = True
        processing_active = False
        camera_input = 0
        if processing_thread and processing_thread.is_alive():
            processing_thread.join()
        processing_thread = None
        return jsonify({"message": "Processing stopped"}), 200

    # Squat Rule-Based
    elif data.get("trigger") == "squat-rule-based":
        if not processing_active:
            stop_processing = False
            processing_active = True
            counter = 0
            stage = None
            error = None

            processing_thread = threading.Thread(target=process_squat)
            processing_thread.start()
            return jsonify({"message": "Squat processing started"}), 200
        else:
            return jsonify({"message": "Processing already active"}), 400

    # Push ups Rule-Based
    elif data.get("trigger") == "pushup-rule-based":
        if not processing_active:
            stop_processing = False
            processing_active = True
            counter_pushup = 0
            stage_pushup = None
            error_pushup = None

            processing_thread = threading.Thread(target=process_pushup)
            processing_thread.start()
            return jsonify({"message": "Pushup processing started"}), 200
        else:
            return jsonify({"message": "Processing already active"}), 400

    elif data.get("trigger") == "jumping-rule-based":
        if not processing_active:
            stop_processing = False
            processing_active = True
            counter_jumping = 0
            stage_jumping = None
            error_jumping = None

            processing_thread = threading.Thread(target=process_jumping_jack)
            processing_thread.start()
            return jsonify({"message": "Jumping processing started"}), 200
        else:
            return jsonify({"message": "Processing already active"}), 400

    elif data.get("trigger") == "pullup-rule-based":
        if not processing_active:
            stop_processing = False
            processing_active = True
            pullup_bad_form = None
            pullup_count = 0

            processing_thread = threading.Thread(target=process_pullup)
            processing_thread.start()
            return jsonify({"message": "Pull Ups processing started"}), 200
        else:
            return jsonify({"message": "Processing already active"}), 400

    elif data.get("trigger") == "leg_raise-rule-based":
        if not processing_active:
            counter_leg_raises = 0
            wrong_counter_leg_raises = 0
            correct_bool_leg_raises = 0
            stage_leg_raises = None
            feedback_leg_raises = ""
            stop_processing = False
            processing_active = True

            processing_thread = threading.Thread(target=process_leg_raises)
            processing_thread.start()
            return jsonify({"message": "Leg Raises processing started"}), 200
        else:
            return jsonify({"message": "Processing already active"}), 400

    elif data.get("trigger") == "bicep-rule-based":
        if not processing_active:
            stop_processing = False
            processing_active = True
            bicep_left_count = 0
            bicep_right_count = 0
            bicep_bad_left_form = False
            bicep_bad_right_form = False

            processing_thread = threading.Thread(target=process_bicep)
            processing_thread.start()
            return jsonify({"message": "Bicep processing started"}), 200
        else:
            return jsonify({"message": "Processing already active"}), 400

    elif data.get("trigger") == "front_raise-rule-based":
        if not processing_active:
            error_left_front_raises = "None"
            error_right_front_raises = "None"
            counter_right_front_raises = 0
            counter_left_front_raises = 0
            stop_processing = False
            processing_active = True

            processing_thread = threading.Thread(target=process_front_raises)
            processing_thread.start()
            return jsonify({"message": "Front Raises processing started"}), 200
        else:
            return jsonify({"message": "Processing already active"}), 400

    elif data.get("trigger") == "bench-rule-based":
        if not processing_active:
            error_bench_press = "None"
            counter_bench_press = 0
            stop_processing = False
            processing_active = True

            processing_thread = threading.Thread(target=process_bench_press)
            processing_thread.start()
            return jsonify({"message": "Bench Press processing started"}), 200
        else:
            return jsonify({"message": "Processing already active"}), 400

    # Plank Correction
    elif data.get("trigger") == "plank-correction":
        if not processing_active:
            stop_processing = False
            processing_active = True
            plank_result = None

            processing_thread = threading.Thread(target=process_plank_correction)
            processing_thread.start()
            return jsonify({"message": "Plank correction started"}), 200
        else:
            return jsonify({"message": "Processing already active"}), 400

    #Classification
    elif data.get("trigger") == "classification":
        if not processing_active:
            stop_processing = False
            processing_active = True
            final_confidence = 0.0
            final_prediction = "Evaluating..."
            bicep_left_count = 0
            bicep_right_count = 0
            bicep_bad_left_form = False
            bicep_bad_right_form = False

            processing_thread = threading.Thread(target=live_classification(class_model,92,INDEX_TO_LABEL_classification))
            processing_thread.start()
            return jsonify({"message": "Classification started"}), 200
        else:
            return jsonify({"message": "Processing already active"}), 400

    # elif data.get("trigger") == "camera-mode-selection":
    #     print("SELECTING CAMERA MODE")
    #     if data.get("camera-mode") == "webcam":
    #         camera_input = 0
    #         print(camera_input)
    #     else:
    #         VIDEO_SAVE_PATH = r'D:\FCIS\Fourth Year\GP\Application\GEMS\Videos'
    #
    #         print("BEFORE FILE")
    #         video_file = request.files.get("video-file")
    #         if video_file:  # ensure file exists
    #             print("RECIVED FILE!")
    #             os.makedirs(VIDEO_SAVE_PATH, exist_ok=True)
    #             camera_input = os.path.join(VIDEO_SAVE_PATH, video_file.filename)
    #             video_file.save(camera_input)
    #             print("Saved video to:", camera_input)
    #         else:
    #             print( "No video file received")

    return jsonify({"error": "Invalid trigger"}), 400

@app.route('/status', methods=['GET'])
def get_status():
    return jsonify({
        "counter": counter,
        "stage": stage,
        "error": error,
        "frame": current_frame,
        "plank_feedback": plank_result["feedback"] if plank_result else "N/A",
        "plank_confidence": plank_result["confidence"] if plank_result else "N/A",
        "bicep_left_count": bicep_left_count,
        "bicep_right_count": min(bicep_right_count, 1),
        "bicep_bad_left_form": bicep_bad_left_form,
        "bicep_bad_right_form": bicep_bad_right_form,
        "final_action": final_prediction_classification,
        "avg_confidence": round(final_confidence_classification, 2),
        "counter_jumping": counter_jumping,
        "stage_jumping": stage_jumping,
        "error_jumping": error_jumping,
        "counter_pushup": counter_pushup,
        "stage_pushup": stage_pushup,
        "error_pushup": error_pushup,
        "pullup_count": pullup_count,
        "pullup_bad_form": pullup_bad_form,
        "counter_leg_raises": counter_leg_raises,
        "feedback_leg_raises": feedback_leg_raises,
        "error_left_front_raises": error_left_front_raises,
        "error_right_front_raises": error_right_front_raises,
        "counter_right_front_raises": counter_right_front_raises,
        "counter_left_front_raises": counter_left_front_raises,
        "counter_bench_press": counter_bench_press,
        "error_bench_press": error_bench_press,
    })

if __name__ == '__main__':
    app.run(host="0.0.0.0", port=5000)
